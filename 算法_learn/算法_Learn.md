---
title: 算法
---

# 1、8种常用排序算法稳定性分析
来源：https://blog.csdn.net/J080624/article/details/86828483

选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法

冒泡排序、插入排序、归并排序和基数排序都是稳定的排序算法。

## 1.1 为什么要区分排序算法的稳定性？
排序算法的稳定性通俗地讲就是能<font size=4>**保证排序前两个相等的数据其在序列中的先后位置顺序与排序后它们两个先后位置顺序相同**</font>。
再简单具体一点，如果 `i` 和 `j` 相等，`i` 原来在 `j` 位置前，排序后 `i` 仍然是在 `j` 位置前。

① 如果排序算法是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所利用。
基数排序就是这样，先按低位排序，逐次按高位排序，那么，低位相同的数据元素其先后位置顺序即使在高位也相同时是不会改变的。

② 学习排序原理时，可能编的程序里面要排序的元素都是简单类型，实际上真正应用时，可能是对一个复杂类型（自定义类型）的数组排序，而排序的键值仅仅只是这个元素中的一个属性，对于一个简单类型，数字值就是其全部意义，即使交换了也看不出什么不同。
但是，对于复杂类型，交换的话可能就会使原本不应该交换的元素交换了。

比如：一个“学生”数组，欲按照年龄排序，“学生”这个对象不仅含有“年龄”，还有其它很多属性。
假使原数组是把学号作为 _主键由小到大_ 进行的数据整理。而稳定的排序会保证比较时如果两个学生年龄相同，一定不会交换。
那也就意味着尽管是对 _“年龄”_ 进行了排序，但是 _学号顺序_ 仍然是 _由小到大_ 的要求。

## 1.2 8种常见排序算法稳定性分析
### 冒泡排序
冒泡排序就是把小的元素往前调（或者把大的元素往后调）。注意是相邻的两个元素进行比较，而且是否需要交换也发生在这两个元素之间。

所以，如果两个元素相等，我想你是不会再无聊地把它们俩再交换一下。

如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个元素相邻起来，最终也不会交换它俩的位置，所以相同元素经过排序后顺序并没有改变。

所以**冒泡排序是一种稳定排序算法**。
<hr>

### 选择排序
选择排序即是给每个位置选择待排序元素中当前最小的元素。比如给第一个位置选择最小的，在剩余元素里面给第二个位置选择次小的，依次类推，直到第n-1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。

那么，在一趟选择时，如果当前锁定元素比后面一个元素大，而后面较小的那个元素又出现在一个与当前锁定元素相等的元素后面，那么交换后位置顺序显然改变了。

举个例子：序列5 8 5 2 9， 我们知道第一趟选择第1个元素5会与2进行交换，那么原序列中两个5的相对先后顺序也就被破坏了。

所以**选择排序不是一个稳定的排序算法**。
<hr>

### 插入排序
插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，也就是第一个元素（默认它有序）。

比较是从有序序列的末尾开始，也就是把待插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面。

否则一直往前找直到找到它该插入的位置。如果遇见一个与插入元素相等的，那么把待插入的元素放在相等元素的后面。

所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序仍是排好序后的顺序，所以**插入排序是稳定的**。
<hr>

### 快速排序
快速排序有两个方向，左边的i下标一直往右走（当条件`a[i] <= a[center_index]`时），其中`center_index`是中枢元素的数组下标，一般取为数组第0个元素。

而右边的`j`下标一直往左走（当`a[j] > a[center_index]`时）。

如果i和j都走不动了，`i <= j`, 交换`a[i]`和`a[j]`,重复上面的过程，直到`i>j`。交换`a[j]`和`a[center_index]`，完成一趟快速排序。

在中枢元素和`a[j]`交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为 5 3 3 4 3 8 9 10 11

现在中枢元素5和3(第5个元素，下标从1开始计)交换就会把元素3的稳定性打乱。

所以**快速排序是一个不稳定的排序算法**，不稳定发生在中枢元素和`a[j]`交换的时刻。
<hr>

### 归并排序
归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换)，然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。

可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定性。

那么，在短的有序序列合并的过程中，稳定是是否受到破坏？

没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。

所以，**归并排序也是稳定的排序算法**。
<hr>

### 基数排序
基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。

有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序，最后的次序结果就是高优先级高的在前，高优先级相同的情况下低优先级高的在前。

**基数排序基于分别排序，分别收集，所以其是稳定的排序算法**。
<hr>

### 希尔排序
希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快。当元素基本有序时，步长很小，插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(N^2)好一些。

由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱。

所以**希尔排序是不稳定的排序算法**。
<hr>

### 堆排序
我们知道堆的结构是节点i的孩子为2*i和2*i+1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。

在一个长为n的序列，堆排序的过程是从第n/2开始和其子节点共3个值选择最大（大顶堆）或者最小（小顶堆），这3个元素之间的选择当然不会破坏稳定性。

但当为n/2-1, n/2-2, ...1这些个父节点选择元素时，就会破坏稳定性。有可能第n/2个父节点交换把后面一个元素交换过去了，而第n/2-1个父节点把后面一个相同的元素没有交换，那么这2个相同的元素之间的稳定性就被破坏了。

所以，**堆排序不是稳定的排序算法**。
<hr>


# 2、字符串搜索算法
来源：https://www.cnblogs.com/myphoebe/archive/2010/08/06/1794252.html

## 2.1 单模式匹配

就是在一些文本中查找某一个子字符串的算法，效率较高的有以下几种。

### 2.1.1 KMP算法
全称Knuth-Morris-Pratt算法 预处理时间Θ(m) 匹配搜索时间 Θ(n)
```cpp
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

const int * get_prefix(const char * P)
{
     int * pi = (int *)malloc(sizeof(int) * strlen(P));
     pi[0] = -1;
     int i = 1;
     int j = -1;
     while (P[i])
     {
        while (j >= 0 && P[j + 1] != P[i])
        {
            j = pi[j];
        }
        if (P[j + 1] == P[i])
        {
            ++j;
        }
        pi[i] = j;
        ++i;
     }
     return pi;
}

void kmp_match(const char * T, const char * P)
{
   const int * pi = get_prefix(P);
    int i = 0;
    int j = -1;
    while (T[i])
    {
        while (j >= 0 && P[j + 1] != T[i])
        {
            j = pi[j];
        }
        if (P[j + 1] == T[i])
        {
            ++j;
        }
        if (0 == P[j + 1])
        {
            printf("%s\n", T + i - j);
            j = pi[j];
        }
        ++i;
    }
    free(pi);
}

int main(int argc, char * argv[])
{
    kmp_match("abcdabcdabcdabcd", "abc");

    return 0;
}
```


参考：《算法导论》

```cpp
/*
* Knuth-Morris-Pratt 字符串匹配算法的三种实现。
* 匹配部分都一样，差异只在求 next 数组。:)
*/

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

/*
* 实现一
*/
char * kmp1(char * content, char * pattern)
{
   int i;
   int j;
   int len;
   int * next;

   if (NULL == content || NULL == pattern)
   {
       return NULL;
   }

   len = strlen(pattern);
   next = (int *)malloc(len * sizeof(int));

    /* Get the "next" array. */
    next[0] = -1;
    for (i = 1; pattern[i] != 0; ++i)
    {
       j = next[i - 1];
          while (pattern[i - 1] != pattern[j] && j >= 0)
         {
             j = next[j];
          }
         next[i] = j + 1;
    }

     /* Match. */
    i = 0;
    j = 0;
    while (content[i] && pattern[j])
    {
        if (content[i] == pattern[j])
        {
            ++i;
            ++j;
        }
        else
        {
            j = next[j];
            if (-1 == j)
            {
                ++i;
                ++j;
             }
         }
    }
 
    free(next);
 
     if (pattern[j])
     {
        return NULL;
    }
     else
    {
        return &content[i - j];
     }
}
 
 /*
 * 实现二
*/
char * kmp2(char * content, char * pattern)
{
   int i;
   int j;
   int len;
   int * next;

   if (NULL == content || NULL == pattern)
   {
      return NULL;
  }

    len = strlen(pattern);
    next = (int *)malloc(len * sizeof(int));

    /* Get the "next" array. */
     next[0] = -1;
     i = 0;
    j = -1;
    while (pattern[i])
    {
         if (-1 == j || pattern[i] == pattern[j])
         {
             ++i;
            ++j;
             next[i] = j;
        }
        else
         {
             j = next[j];
         }
    }

    /* Match. */
    i = 0;
    j = 0;
    while (content[i] && pattern[j])
    {
        if (content[i] == pattern[j])
         {
            ++i;
             ++j;
        }
        else
         {
            j = next[j];
             if (-1 == j)
            {
                 ++i;
                ++j;
             }
        }
     }

    free(next);
 
    if (pattern[j])
     {
         return NULL;
     }
     else
     {
         return &content[i - j];
     }
}
 
/*
 * 实现三
*
* 实现二的改进，改进处见注释。
 */
char * kmp3(char * content, char * pattern)
{
   int i;
    int j;
    int len;
   int * next;

   if (NULL == content || NULL == pattern)
   {
       return NULL;
   }

   len = strlen(pattern);
   next = (int *)malloc(len * sizeof(int));

   /* Get the "next" array. */
   next[0] = -1;
   i = 0;
   j = -1;
    while (pattern[i])
    {
       if (-1 == j || pattern[i] == pattern[j])
       {
           ++i;
          ++j;

          /* 此处是对实现二的改进。 */
           if (pattern[i] == pattern[j])
           {
               next[i] = next[j];
           }
           else
           {
               next[i] = j;
           }
       }
       else
       {
          j = next[j];
       }
   }

   /* Match. */
   i = 0;
   j = 0;
   while (content[i] && pattern[j])
   {
       if (content[i] == pattern[j])
       {
           ++i;
            ++j;
       }
        else
       {
           j = next[j];
           if (-1 == j)
            {
               ++i;
               ++j;
            }
        }
    }

    free(next);

    if (pattern[j])
     {
        return NULL;
    }
    else
    {
        return &content[i - j];
    }
}

int main(int argc, char * argv[])
{
    printf("%s\n", kmp1(argv[1], argv[2]));
    printf("%s\n", kmp2(argv[1], argv[2]));
    printf("%s\n", kmp3(argv[1], argv[2]));

    return 0;
}
```

### 2.1.2 BM算法
全称Boyer-Moore string search algorithm 预处理时间Θ(m + |Σ|) 匹配搜索时间Ω(n/m), O(n)

## 2.2 有限模式集合匹配
就是在字符串中查找多个子字符串的算法，常用于查找字典中的单词和一些脏字匹配算法

**Aho-Corasick算法**：这是一种字典匹配算法，它用于在输入文本中查找字典中的字符串。时间复杂度是线性的。
基本原理：该算法利用类似后缀树的方法构造一个trie结构，匹配时利用该结构来搜索。

**Aho-Corasick算法**：可以认为是KMP算法在多串查找的扩展。先把所有要查找的串放在一起建一棵trie树。然后从源串的各个位置开始的串到trie树里查找。这样每次查找的复杂度为O（m）,m为最长的子串。总共要查n次，所以复杂度为O(nm)。这只能说是brute force算法在多串下的扩展。所以还要在trie树里添加一些转移，使得源串在匹配过程中不出现回退。假设当前节点为i,源串匹配到字符c,如果节点i不存在c字母对应的转移。这时候应该跳转到一个节点j，从trie树根节点到这个节点的字母组成的字符串，应该是从根节点组成的字符串的后缀，如果有多个这样的节点，则跳转到最短的一个。分析一下这个自动机在匹配时的复杂度。要匹配过程中，源串不回退，所以遍历源串的复杂度为O（n）。但是在匹配失败的时候，会出现跳转，可能要跳转很多次才可以匹配成功。但是注意一点，每次跳转使得深度至少减1，而深度至多跟源串匹配的长度相等，所以可以跳转的次数不会超过源串的长度，所以总的复杂度是O(n)。

要注意一个地方，后缀关系是可以传递的，a是b的后缀，b是c的后缀，则a是c的后缀。所以上面的表达式，最终是把一个串的后有后缀，从长到短串成了一个链表。

难的地方就是自动机的构造。为了便于分析，把建trie树跟增加跳转分成两个过程。假设现在已经建好trie树。要为一个节点增加跳转，最简单的方法是，把根结点到它一路上的字符串组成的字符串，求后缀，再到trie树里查找，因为是求最长的后缀，所以从长到短，逐一去查找，直至找到为止，找到的节点就是要跳转的节点。这种方法的复杂度很高。观察一下，假设在trie树里，i节点是j节点的父结点,j的跳转结点的父结点表示的串，也是i的后缀。反过来说，根据一个节点的父结点的跳转可以快速地找到这个结点的跳转。假设当前节点的父结点的跳转结点为k,下一个要匹配的字符为c，看k是否有c的跳转，如果没有，则k继续跳转。会否出现没有找到合法的跳转，而k又不能再跳转的情况呢？初始的时候，把所有节点的跳转都指向根结点，可以避免这种情况。

在实现的时候，因为跳转总是从深度大的结点跳到深度小的结点，所以对trie树作广度遍历。现在来分析一下构造的复杂度。trie树中结点的总数不会超过待查找的子串的长度和。但是每个结点的查找会进行多次跳转。分析一个子串它对应的一系列节点，每交跳转会使得深度减1，而这些节点的深点至多为子典的长度，所以一个子串对应的所有结点的构造费用之和，不会超过字串的长度，所以总的构造复杂度是跟字符长度和成正比的。


**Commentz-Walter 算法**：是BM算法的自然扩展，它的速度并不快

**Rabin-Karp string search算法**：该算法最差复杂度不好，因此运用的并不广泛。

## 2.3 例子
1. 问题描述

      给定目标字符串 T[0..n-1] （基于 0 的数组，数组长度为 n ），和模式串 P[0..m-1] ，问 P 可否匹配 T 中的任意子串，如果可以，返回匹配位置。

2. 问题分析

直观分析
   brute-force 的蛮力法，适用于较小规模的字符串匹配。

 优化
   主要介绍 3 种优化办法，分别具体为： Rabin-Karp 算法，有限自动机和 KMP 算法。将分为 3 篇博文分别讨论。本小节主要介绍 Rabin-Karp 算法。

 得出算法
   Rabin-Karp 算法（以下简称为 RK 算法），是基于这样的思路：即把串看作是字符集长度进制的数，由数的比较得出字符串的比较结果。例如，给定字符集为∑ ={0,1,2,3,4,5,6,7,8,9} ，∑长度为 d=10 ，那么任何以∑为字符集的串都可看作 d （此处为 10 ）进制的数。

记模式串 P[0..n-1] 对应的数值为 P ， T[0..n-1] 所有长度为 m 的子串对应的数值为 ts ，设 P 和 T 都是基于字符集长度为 | ∑ |=d 的字符串。

那么， ts 即为 T[s..s+m] 对应的数值，这里 0<=s<=n-m-1 。

P = P[m]+d*(P[m-1]+d*(P[m-2]+..)))

同样 t0 也可类似求得。

最重要的是如何从 ts 求出 ts+1 。

ts+1 =T[s+m]+d*(ts +dm-1 *T[s])

注：此处是该算法的关键，即在常数时间内能够计算出下一个 m 长度的字串对应的数值。初看比较抽象，举个例子就比较明白了，设 x=12345 ，现在是已知长度为 3 的数值 234 ，现在要求 345 对应的数值，可以这样来得到： 345 = 5 + 10*(234-102 *2)

3. 算法描述

      求出所有 m 长度子串所对应的数值，对数值进行比较，继而得出子串是否匹配。当模式串长度很大时，这时对应的数值会很大，比较起来比较麻烦，可使用对一个大奇数取模后进行比较。

4. 具体实现

      这里实现的只是m值较小时的情形，大整数需要特定的类的支持（如可自定义大整数类），选取10进制的数是为了方便起见，当然字母也是OK的。

```cpp
#include "iostream"   
#include "string"   
#include "cmath"   
using namespace std;   

  // get the value of the character in the set   
    int getV(char p, string set)   
    {   
        for(int i=0; i<set.length(); i++)   
        {   
           if (p==set[i])   
               return i;   
        }   
       return -1;   
   }   
   // d is the size of the character set   
int RK(string T, string P,string set)   
   {   
       int d = int(set.length());   
       int n = T.length();   
       int m = P.length();   
       int h = pow(double(d), m-1);   
       int p=0;   
       int t = 0;   
       for(int i=0; i<m; i++)   
        {   
            p = d*p + getV(P[i],set);   
            t = d*t + getV(T[i], set);   
        }   
       for (int s=0; s<=n-m; s++)   
        {   
            cout<<"p,t is "<<p<<","<<t<<endl;   
           if (p==t)   
               return s;   
           if (s<n-m)   
                t = getV(T[s+m],set)+d*(t-h*getV(T[s],set));   
        }   
       return -1;   
   }   
int main()   
{   
       // set is the character set   
        string set= "0123456789";   
       // pattern P   
        string P = "2365";   
       // T is the string to match   
        string T = "258569236589780";   
       int i = RK(T, P, set);   
      cout<<"the postition is:"<<i<<endl;   
       return 0;   
}  
```

# 字符串匹配算法：暴力匹配、KMP 算法、Boyer-Moore 算法、Rabin-Karp 算法
https://blog.csdn.net/xhc6666/article/details/136622642

# 字符串搜索算法效率对比：BF\RK\BM\KMP\Sunday
https://blog.csdn.net/weixin_45616285/article/details/128242976

# [唐老狮] A星寻路算法理论基础
来源：https://www.bilibili.com/video/BV1rT4y1g7GS/?spm_id_from=333.999.0.0&vd_source=7326fe06b64e27279f7a29142c1cf0b6

## 了解A星寻路是用来解决什么问题的
是用来计算玩家行进最短路径的

## 了解A星寻路的基本原理
不停地找周围的点，选出一个新的点作为起点，再循环地找，直到找到终点

## 了解A星寻路的详细原理
1. 寻路消耗公式：
	   f(寻路消耗) = g(离起点距离) + h(离终点距离)
2. 开启列表
	   每次把周围的点放入开启列表时，需要进行判断
	   2.1. 不是阻挡
	   2.2. 不是在开启列表或关闭列表中
3. 关闭列表
	   每次把最优点放入关闭列表时，需要进行判断该点是否是终点，如果是则寻路结束，如果不是则继续寻路
4. 格子对象的父格子对象
	   用来确定最终路径（从终点的父格子往前推）
* 如果开启列表为空，则表示为死路


# [唐老狮]【手把手教你】Unity中实现A星寻路算法
来源：https://www.bilibili.com/video/BV147411u7r5/?spm_id_from=333.999.0.0&vd_source=7326fe06b64e27279f7a29142c1cf0b6





[评论]：
感谢UP主用心讲解。
如果你跟我一样是通过本视频实现了A星寻路功能，那么你可能还需要至少两样东西进行优化才能在节点较多的地图中流畅使用A星寻路：
https://blog.csdn.net/yaonai2003/article/details/19234383 (A星进一步优化，让二叉堆更快，更猛。as3版)  跟我一样的新人可以重点看2，3条。
https://blog.csdn.net/Ymiku/article/details/45957107    (A* 算法中二叉堆的使用)
第二篇研究之前，最好先用十几分钟看看视频了解一下什么是二叉堆，这样这里代码就很好消化吸收了。
这两篇都是转载，我确实不知道该怎么找到原文，见谅。
最后再次感谢UP主，也祝各位学运昌隆。



# A星进一步优化，让二叉堆更快，更猛。as3版
来源：https://blog.csdn.net/yaonai2003/article/details/19234383

二叉堆优化提高了A星一大步，但是想要更快，更猛，还不能停步。这两天整理自己的A星，啃了些网上搜的一些大神源码，今天整理下思路分享下。

A星原理和二叉优化在天地会文章很多，这里就不多说了，要读此文先，提前是对A星有一定了解。(本文思路源于别人代码，不是我原创，呵呵)

优化大多是用空间换时间，把过程的计算量放到初始存入内存。下面直接进入正题吧。

## 一、障碍邻点的预计算。
判断周围格子是否有障碍还有计算格子的cost价值，如果在每次寻路的时候才去算就太浪费了，因为每次寻路的时候每个格子相邻的障碍是不会变的，价值cost也不变，我们大可以把这块计算抽出放到初始地图的时候计算。步骤如下:

1. 给节点添加邻节点数组nodeLinks，和邻节点价值组costLinks。(也可建一个linkNode对象，对象里面有节点和价值两属性，反正两数组是个映对关系),保证nodeLinks[i]的价值是costLinks[i]

2. 地图初始好的时候遍历每个格子，计算出其周围的所有非障碍的格子，并加入节点邻数组中存起。计算每个邻节点的价值，映对存入节点价值组。

3. 寻路的时候判断节点四周有哪些格子直接从当前计算的节点的nodeLinks属性取即可，不需要再计算。

预计算可节省很多性能，不过缺点是初始的时候很慢。 

## 二、Array数组优化
Array的indexOf和shift方法是很吃性能的，很多人的A星在while里面有这两个东西，这是那几百毫秒慢下的原因。怀疑的同学可以自己写个1万次的大循环调用这两个方法看看。要判断节点是否在开户组里面，普通人的做法是用indexOf，其实这个方式可以换成以下处理

1. 给节点添加isOpen:Boolean属性

2. 每次push节点到打开数组的里面设节点的isOpen为true

3. 节点移出打开列表时，将节点的isOpen属性设为false

4. 判断节点是否在开启列表时只需要判断isOpen即可

判断关闭同理，另外还有会用上indexOf的地方是二叉堆里面，干掉方式略。

将关闭组添加到通过父节点添加到返回路径时，很多人会用shift，把节点一个个添到path数组里面，这也是个慢的因素。可以换成push方式，push不会改变索引，所以效率很高。将关闭节点组数据通过push加入路径后，再调用reverse把数组倒置，结果跟用shift一样，不过用时可大不一样。

## 三、打开关闭标记，换掉不用重置
用isOpen来替代indexOf大大提升了一步性能，可是每次寻路完之后会有个问题，那就是要把节点重置，就是把所有打开和关闭列表里面的节点的isOpen,isClose设false。呵呵，虽然这个重置吃的性能相当小，不过本着追求精神，我又找出了更变态的方式。步骤如下

1. 每次A星计算设一唯一自增标记markIndex,每计算一次寻路，这个整型属性+1

2. 把节点里面的isOpen和isClose布尔属性改成openMark,closeMark整型属性。

3. 加入列表时把openmark设为本次计算的自动标记markIndex，移出列表设为-1（或随便一个不等于markIndex的数)

4. 判断是否在打开列表中只需判断if(openMark == markIndex)即可

5. 某次寻路计算完之后markIndex+1

因为自增标记每次计算都不一样，所以节点的openMark不需要重置，下次也能继续用。这个方式带来的性能提升很微小不多，不追求那几十毫秒的大可无视。

## 四、减少while里面get/set/function
get/set的性能其实很高，不过在项目中，大量的格子一经过while方法就是数万次的运算，虽然每次性能相差很少，但量一大起来效率就明显了。不信的人可以写个大循环在里面用getter和public属性的方式对比一下，性能相差三四倍。如果节点的f,g,h,x,y这些属性用了接口get/set，那个运算毫秒相差就很明显了。function 是代码设计不可省的东西，这一步优化只适合在A星的while中用，正常项目中可省不得。

## 五、位运算，再提一提微小的性能
在二叉堆中的除以2，`num/2 ==n um* 0.5==num >> 1`，这三个种计算方式最快的明显是第三种，虽然可读性差些，不过效率还是有点提升滴。另外num*2 == num<<1;也可提升些性能



# A* 算法中二叉堆的使用
来源：https://blog.csdn.net/Ymiku/article/details/45957107

这里讲解的二叉堆，其实是以堆的形式存在的二叉树，这个特殊的结构把A* 算法对开启列表的排序需求演绎的出神入化，毫无疑问是A* 的最佳拍档。

A* 算法中最缓慢的部分就是在开启列表中寻找F值最低的节点或者方格。取决于地图的大小，你可能有十几，成百甚至上千的节点需要在某个时候使用A* 搜索。无需多讲，反复搜索这么大的列表会严重拖慢整个过程。然而，这些时间在极大程度上受你存储列表的方式影响。

 
## 有序和无序的开启列表：简单的方法

最简单的方法就是顺序存储每个节点，然后每次需要提取最低耗费元素的时候都遍历整个列表。这提供可快速的插入速度，但是移除速度可能是最慢的，因为你需要检查每个元素才能够确定哪个才是F值最低的。

通常你可以保持你列表处于有序状态来提升效率。这花费了稍微多一点的预处理时间，因为你每次插入新元素都必须把他们放在恰当的位置。不过移除元素倒是很快。你只要移除第一个元素就可以了，它一定是F值最低的。

有很多方法可以保持你的数据有序（选择排序，冒泡排序，快速排序，等等）并且你可以用你最熟悉的搜索引擎找到这方面的文章。不过我们至少可以先提几种想法。最简单的方法可能是，当你需要添加新元素的时候，从列表开始的地方，依次比较每个元素的F值和要插入的F值的大小。一旦找到一个相等或者更高的F值，你就可以把新元素插入到列表中那个元素的前面。

这种方法可以通过保持列表中所有元素的平均值来得到改进，使用这个平均值来决定是从头（如上所说）还是从尾开始处理。总的说来，比平均F值低的新元素将被从头开始处理，而比平均F值高的则从末尾开始。这种方法可以节省一半的时间。

复杂一些，但是更快的方法是把这一想法提高到新的层次使用快速排序，它基本上是从比较新元素和列表中间元素的F值开始。如果新元素的F值低，你接着把它和1/4处元素进行比较，如果还是更低你就比较它和1/8处的元素，如此这般，不断的折半你的列表并且比较，直到找到合适的位置。这个描述很简单，你可能会想到网上寻找快速排序的更多资料。这比至此描述的任何方法都快。


## 二叉堆

二叉堆和刚才说的快速排序很像，经常被那些苛求A* 速度的人使用。二叉堆平均提高寻路速度2-3倍，对于包含大量节点的地图(也就是说100×100节点或者更多）效果更明显。友情提醒，然而二叉堆很难处理，除非你使用含有大量节点的地图，速度至关重要，否则不值得为它头痛。

在有序列表中，每个元素都按照由低到高或由高到低的顺序保存在恰当的位置。这很有用，但是还不够。事实上，我们并不关心数字127是否比128在更低的位置上。我们只是想让F值最低的元素能放在列表顶端以便容易访问。列表的其他部分即使是混乱的也不必在意。列表的其他部分只有在我们需要另一个F值最低的元素的时候，才有必要保持有序。

基本上，我们真正需要的是一个“堆”，确切的说，是个二叉堆。二叉堆是一组元素，其中最大或者最小（取决于需要）的元素在堆顶端。既然我们要寻找F值最小的元素，我们就把它放在堆顶端。这个元素有两个子节点，每个的F值等于，或者略高于这个元素。每个子节点又有两个子节点，他们又有和他们相等或略高的子节点。。。依次类推。

这里是一个堆可能的样子：

注意，F值最低的元素(10)在最顶端，第二低的元素(20)是它的一个子节点。可是，其后就没有任何疑问了。在这个特定的二叉堆里，第三低的元素是24，它离堆顶有两步的距离，它比30小，但是30却在左侧离堆顶一步之遥的地方。简单的堆放，其他的元素在堆的哪个位置并不重要，每个单独的元素只需要和它的父节点相等或者更高，而和它的两个子节点相比，更低或者相等，这就可以了。这些条件在这里都完全符合，所以这是个有效的二叉堆。

很好，你可能会想，这的确有趣，但是如何把它付诸实施呢？嗯，关于二叉堆的一个有趣的事实是，你可以简单的把它存储在一个一维数组中。

在这个数组中，堆顶端的元素应该是数组的第一个元素(是下标1而不是0)。两个子节点会在2和3的位置。这两个节点的4个子节点应该在4－7的位置。

总的来说，任何元素的两个子节点可以通过把当前元素的位置乘以2（得到第一个子节点）和乘2加1（得到第二个子节点）来得到。就这样，例如堆中第三个元素（数值是20）的两个子节点，可以在位置2*3 = 6和2*3 +1 = 7这两个位置找到。那两个位置上的数字非别是30和24，当你查看堆的时候就能理解。

你其实不必要知道这些，除了表明堆中没有断层之外知道这些没有任何价值。7个元素，就完整的填满了一个三层堆的每一层。然而这并不是必要的。为了让我们的堆有效，我们只需要填充最底层之上的每一行。最底层自身可以是任意数值的元素，同时，新的元素按照从左到右的顺序添加。这篇文章描述的方法就是这样做的，所以你不必多虑。


### 往堆中添加新元素

当我们实际在寻路算法中使用二叉堆的时候，还需要考虑更多，但是现在我们只是学习一下如何使用二叉堆。我跳过这部分以便更容易理解基本的东西。我会在文章后面的部分给出处理这一切的完整公式，但了解这些细节仍然十分重要。

大致的，为了往堆里添加元素，我们把它放在数组的末尾。然后和它在当前位置/2 处的父节点比较，分数部分被圆整。如果新元素的F值更低，我们就交换这两个元素。然后我们比较这个元素和它的新父节点，在（当前位置）/2 ，小数部分圆整，的地方。如果它的F值更低，我们再次交换。我们重复这个过程直到这个元素不再比它的父节点低，或者这个元素已经到达顶端，处于数组的位置1。

我们来看如何把一个F值为17的元素添加到已经存在的堆中。我们的堆里现在有7个元素，新元素将被添加到第8个位置。这就是堆看起来的样子，新元素被加了红色。

10 30 20 34 38 30 24 ==17==


接下来我们比较它和它的父节点，在 8/2 也就是 4的位置上。位置4当前元素的F值是34。既然17比34低，我们交换两元素的位置。现在我们的堆看起来是这样的:

10 30 20 ==17== 38 30 24 34

 
然后我们把它和新的父节点比较。因为我们在位置4，我们就把它和 4/2 = 2 这个位置上的元素比较。那个元素的F值是30。因为17比30低，我们再次交换，现在堆看起来是这样的：

10 ==17== 20 30 38 30 24 34


接着我们比较它和新的父节点。现在我们在第二个位置，我们把它和 2/2 = 1，也就是堆顶端的比较。这次，17不比10更低，我们停止，堆保持成现在的样子。


### 从堆中删除元素

从堆中删除元素是个类似的过程，但是差不多是反过来的。首先，我们删除位置1的元素，现在它空了。然后，我们取堆的最后一个元素，移动到位置1。在堆中，这是结束的条件。以前的末元素被加了红色。

==34== 17 20 30 38 30 24

 
然后我们比较它和两个子节点，它们分别在位置(当前位置*2)和(当前位置* 2 + 1)。如果它比两个子节点的F值都低，就保持原位。反之，就把它和较低的子节点交换。那么，在这里，该元素的两个子节点的位置在 1 * 2 = 2和 1* 2 + 1 = 3。显然，34不比任何一个子节点低，所以我们把它和较低的子节点，也就是17，交换。结果看起来是这样：

17 ==34== 20 30 38 30 24

 
接着我们把它和新的子节点比较，它们在 2 * 2 = 4，和2 * 2 + 1 = 5的位置上。它不比任何一个子节点低，所以我们把它和较低的一个子节点交换（位置4上的30）。现在是这样：

 
17 30 20 ==34== 38 30 24

 
最后一次，我们比较它和新的子节点。照例，子节点在位置 4 * 2 = 8和 4 * 2+1 = 9的位置上。但是那些位置上并没有元素，因为列表没那么长。我们已经到达了堆的底端，所以我们停下来。


## 二叉堆为什么这么快？

现在你知道了堆基本的插入和删除方法，你应该明白为什么它比其他方法，比如说插入排序更快。假设你有个有1000个节点的开启列表，在一格有很多节点的相当大的地图上，这不是不可能（记住，即使是100×100的地图，上面也有10,000个节点）。如果你使用插入排序，从起点开始，到找到新元素恰当的位置，在把新元素插入之前，平均需要做500次比较。

使用二叉堆，你从底端开始，可能只要1－3次比较就能把新元素插入到正确的位置。你还需要9次比较用来从开启列表中移除一个元素，同时保持堆仍然有序。在A*中，你通常每次只需要移除一个元素(F值最低的元素)，在任意位置添加0到5个新节点(就像主文章里描述的2D寻路)。这总共花费的时间大约是同样数量节点进行插入排序的1%。差别随你地图的增大(也就是节点更多)呈几何增长。地图越小，就越没优势，这也是为什么你的地图和节点越少，二叉堆的价值就越低的原因。

顺便，使用二叉堆并不意味着你的寻路算法会快100倍。在下面还讲了一些棘手的问题。额外的，A* 不仅仅是为开启列表排序。然而，根据我的经验，用二叉堆在大部分场合可以提高2－3倍的速度，更长的路径，速度提高的更多。

### 在堆中添加新元素(第二部分）        

好，我们实际的把这种技术用在A* 寻路的开启列表排序中。我们使用的技术和先前描述的大体相同。

我们添加到开启列表中的第一个元素，一般是起始节点，当我们往开启列表中添加新元素的时候，首先我们计算G，H和F值，然后把它添加到开启列表的底部，然后我们依次把它和父节点比较直到它到达正确的位置。这是这些操作的代码：

```c#
private final void addPointResize()
 {
		int last = open.length - 1;

		while (last > 1)
		{
				inthalf = last>>1;

			   if(open[last][ID_F]>=open[half][ID_F])
				{
					   break;
				}
				inttmp[] = open[last];
			   open[last] = open[half];
			   open[half] = tmp;
				last>>= 1;
		}
 }
```


### 从堆中删除元素(第二部分)

无疑，我们不能只建立堆，当不需要的时候，我们也要从堆中删除元素。特别的，在A* 寻路中，我们在检查和切换到关闭列表之后，从堆顶需要删除F值最低的元素。

如前所述，你从把末元素移动到堆顶开始，接着我们需要依次比较它和两个子节点的数值。如果它的F值更高，我们就把它和更低F值的子节点交换。然后我们把它和新的子节点比较（看它是否更低）。如果它的F值比两个子节点更高，我们把它和较低的一个交换。我们重复这个过程直到找到它的正确位置。
```c#
private final void removePointResize()
 {
		int last = open.length - 1;
		open[1] = open[last];

		open = resizeArray(open, last, -1);
		last = open.length - 1;

		int head = 1;

		while((head<<1)+1 <= last)
		{
				intchild1 = head<<1;

				intchild2 = child1+1;

				intchildMin = open[child1][ID_F]<open[child2][ID_F]?child1:child2;

			   if(open[head][ID_F]<=open[childMin][ID_F])
				{
					   break;
				}

				inttmp[] = open[head];

			   open[head] = open[childMin];

				open[childMin]= tmp;

				head =childMin;
		}
 }
```


## 对开启列表的元素重排序

就如在主文章中描述的，有时候你会发现现有的开启列表中的元素会改变。这种情况发生的时候，我们不必要取出这个元素重新来过。只要从当前位置开始，用它新的（更低的）F值和它的父节点比较。如果它的F值低到足以替换它的父节点，你就把它替换掉（不然你就会得到一个错误的堆，一切都完了）。一般，你使用和“在堆中添加新元素”的小节中相同的代码，并做额外处理如下：
```c#
private final void resetPointResize(inti)
 {
		int last = i;

		while (last > 1)
		{
				inthalf = last>>1;

			   if(open[last][ID_F]>=open[half][ID_F])
				{
					   break;
				}

				inttmp[] = open[last];

			   open[last] = open[half];

			   open[half] = tmp;

				last>>= 1;
		}
 }
```


# 五大常见算法策略之——动态规划策略（Dynamic Programming）
https://www.cnblogs.com/vfdxvffd/p/12302575.html

# 五大常见算法策略之——回溯策略
https://www.cnblogs.com/vfdxvffd/p/12484932.html

# 五大常见算法策略之——递归与分治策略
https://www.cnblogs.com/vfdxvffd/p/12165239.html


# 常见算法技巧之——双指针思想
https://www.cnblogs.com/vfdxvffd/p/13734111.html


# 算法总结---最常用的五大算法（算法题思路）
https://www.cnblogs.com/Renyi-Fan/p/10815119.html


# ↓↓↓ [幽灵化石] ↓↓↓
https://www.cnblogs.com/yasheng?page=1
包含数据库系统概论
# 算法设计与分析（一）时间复杂度、限界函数、基本数据结构、递推
https://www.cnblogs.com/yasheng/p/12502203.html

# 算法设计与分析（二）五大算法--分治法、贪心方法、动态规划、回溯法、分支界限法
https://www.cnblogs.com/yasheng/p/12503015.html

# 算法设计与分析（三）分治法--快速排序的递归和非递归实现
https://www.cnblogs.com/yasheng/p/12516757.html

# 算法设计与分析（三）分治法--棋盘覆盖问题
来源：https://www.cnblogs.com/yasheng/p/12517157.html
https://blog.csdn.net/q547550831/article/details/51541527

# 算法设计与分析（三）贪心算法--活动安排问题
来源：https://www.cnblogs.com/yasheng/p/12517250.html

活动安排问题
https://blog.csdn.net/qq_40452317/article/details/88875384

贪心算法汇总--喷水装置问题、会场安排问题、过河问题
https://blog.csdn.net/liujiuxiaoshitou/article/details/69728714

# 算法设计与分析（三）动态规划--0/1背包问题
来源：https://www.cnblogs.com/yasheng/p/12523710.html

0/1背包问题详解，包括为何贪心不能实现，为何要倒序遍历状态
https://www.cnblogs.com/techflow/p/12521969.html

反证法 如何证明最优子结构
https://blog.csdn.net/qq_25974431/article/details/81535318

# 算法设计与分析（三）动态规划--多段图最短路径、链阵
来源：https://www.cnblogs.com/yasheng/p/12524036.html

多段图最短路径
https://blog.csdn.net/u012432778/article/details/41623961

矩阵链
https://www.cnblogs.com/Jason-Damon/p/3231547.html#3882147

# 算法设计与分析（三）回溯法---八皇后问题（包含全排列）
https://www.cnblogs.com/yasheng/p/12709705.html

# ↑↑↑ [幽灵化石] ↑↑↑

# 五大经典算法（贪婪、动态规划、分治、回溯、分支限界法）及其联系和比较
https://blog.csdn.net/vivian_ll/article/details/103253664

# 五大基础算法（枚举、递归、分治、贪心、模拟）
https://blog.csdn.net/linj_m/article/details/17393031